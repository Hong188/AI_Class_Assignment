import torch

# Check if GPU is available and set the device to be used
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 1. Check if PyTorch or CUDA is available
print("PyTorch is successfully imported!")
print(f"PyTorch version: {torch.__version__}")
if torch.cuda.is_available():
    print("CUDA is available! Device count:", torch.cuda.device_count())
    print("Current CUDA device:", torch.cuda.get_device_name(0))
else:
    print("CUDA is not available. Using CPU.")

# 2. Create a Tensor and move it to the GPU
# Assign the tensor directly to the GPU by specifying the 'device'
test_tensor = torch.tensor([1, 2, 3, 4, 5], device=device)

# 3. Check the tensor's device
print("\nTest tensor created:", test_tensor)
print("Tensor shape:", test_tensor.shape)
print("Tensor device:", test_tensor.device)

# 4. Perform calculation
# The calculation is performed on the GPU because the tensor is on the GPU
test_result = test_tensor**2
print("\nBasic operation test (squaring):", test_result)

print("\nPyTorch is working correctly!")
